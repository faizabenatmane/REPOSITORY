{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade keras\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_rERRMwHTYfP",
        "outputId": "d8a88e4c-5fb6-4f06-aa36-008c48d180e2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "import re\n",
        "\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory"
      ],
      "metadata": {
        "id": "43ItpDLlUL94"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb3f8fc-c57a-4fec-99e9-2591e24a608a",
        "id": "i0Erf5y-sWVt"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.14.0)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "!pip install --upgrade keras\n",
        "\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('DataTrain.csv')\n",
        "# Keeping only the neccessary columns\n",
        "data = data[['text','sentiment']]\n"
      ],
      "metadata": {
        "id": "SNV6qGGdUUGV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and keep rows where no cell in any column contains a string with length > 12\n",
        "data = data[~data.applymap(lambda x: isinstance(x, str) and len(x) > 12).any(axis=1)]\n",
        "\n",
        "# Reset the index after dropping rows\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(data)"
      ],
      "metadata": {
        "id": "ekDl5Q6AqKrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ca4e235-c0d3-4b3d-ef8e-7c9d34a11378"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             text sentiment\n",
            "0            Kpai  positive\n",
            "1     Really Good  positive\n",
            "2       Not Bad..  positive\n",
            "3      Perfect ðŸ‘ŒðŸ‘Œ  positive\n",
            "4         Usefull  positive\n",
            "..            ...       ...\n",
            "794          heyy   neutral\n",
            "795      Its okay  negative\n",
            "796    Great idea  positive\n",
            "797  Back to work   neutral\n",
            "798      Surgery.   neutral\n",
            "\n",
            "[799 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data['text']\n",
        "\n",
        "# Tokenize your text data\n",
        "tokenizer = Tokenizer(num_words=10000)\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# Find the maximum sequence length\n",
        "max_sequence_length = max(len(seq) for seq in X)\n",
        "\n",
        "# Pad sequences to a fixed length (use max_sequence_length as input_length)\n",
        "X = pad_sequences(X, maxlen=max_sequence_length)"
      ],
      "metadata": {
        "id": "HcFivNf6vB8I"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 128\n",
        "lstm_out = 196\n",
        "max_features = 10000  # You can adjust this value based on your dataset size and vocabulary.\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_dim, input_length=X.shape[1]))  # Corrected max_features\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwZrtl9VK8m",
        "outputId": "b2ce3f62-dda7-4117-f1b8-701fed662062"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 5, 128)            1280000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 5, 128)            0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 196)               254800    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 394       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1535194 (5.86 MB)\n",
            "Trainable params: 1535194 (5.86 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer"
      ],
      "metadata": {
        "id": "faElDzanspnO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5215479-552e-4002-d9df-45c5c9946cad"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = stopwords.words('english')\n",
        "stemmer = SnowballStemmer('english')"
      ],
      "metadata": {
        "id": "F8IQNKz9ssrF"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "# using regex to remove hyperlinks and other using links\n",
        "text_clean = \"@\\S+|https?:\\S+|http?:\\S|[^A-Za-z0-9]+\""
      ],
      "metadata": {
        "id": "bRMolSsVsweU"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = data.copy()\n",
        "x = df1.text[3]\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5kG3UF4Hs69h",
        "outputId": "25a53ac7-18df-4f0e-a5ea-fb32e4a493a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Perfect ðŸ‘ŒðŸ‘Œ'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xx = re.sub(text_clean, ' ', str(x).lower()).strip()\n",
        "z = []\n",
        "for token in xx.split():\n",
        "   z.append(token)\n",
        "print (z)\n",
        "\" \".join(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "uBblvT4_s9Lv",
        "outputId": "efddb864-beaa-4fc9-d303-fea25d093469"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['perfect']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'perfect'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i, words in enumerate(stopwords):\n",
        "  if words==\"good\":\n",
        "    print (i, words)\n",
        "    break"
      ],
      "metadata": {
        "id": "EjwCWfJEs_km"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# function to cleanup the text\n",
        "def preprocess(text, stem=False):\n",
        "  text = re.sub(text_clean, ' ', str(text).lower()).strip()\n",
        "  tokens = []\n",
        "  for token in text.split():\n",
        "    if token not in stopwords:\n",
        "      if stem:\n",
        "        tokens.append(stemmer.stem(token))\n",
        "      else:\n",
        "        tokens.append(token)\n",
        "  return \" \".join(tokens)"
      ],
      "metadata": {
        "id": "qmDVCGaNtEH_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter and keep rows where no cell in any column contains a string with length > 12\n",
        "df1 = df1[~df1.applymap(lambda x: isinstance(x, str) and len(x) > 12).any(axis=1)]\n",
        "\n",
        "# Reset the index after dropping rows\n",
        "df1.reset_index(drop=True, inplace=True)\n",
        "\n",
        "# Print the resulting DataFrame\n",
        "print(df1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nipD9asctGtU",
        "outputId": "a89c7e24-91c2-4dd3-ef13-b6d7514e7b57"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             text sentiment\n",
            "0            Kpai  positive\n",
            "1     Really Good  positive\n",
            "2       Not Bad..  positive\n",
            "3      Perfect ðŸ‘ŒðŸ‘Œ  positive\n",
            "4         Usefull  positive\n",
            "..            ...       ...\n",
            "794          heyy   neutral\n",
            "795      Its okay  negative\n",
            "796    Great idea  positive\n",
            "797  Back to work   neutral\n",
            "798      Surgery.   neutral\n",
            "\n",
            "[799 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = data.copy()\n",
        "df1.text = df1.text.apply(lambda x: preprocess(x))\n",
        "df1[\"text\"]\n",
        "df=df1"
      ],
      "metadata": {
        "id": "4__I59D4tKNA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import nltk\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from textblob import Word\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "import wordcloud\n",
        "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "YgEPbBJ4tUS1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check if there are any null values\n",
        "# Select the desired columns\n",
        "df = df[['text', 'sentiment']]\n",
        "\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-4Qj6KStbkm",
        "outputId": "980eece0-6007-49a1-95fa-8e64e491b2d7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text         0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoded the target column\n",
        "lb=LabelEncoder()\n",
        "df['sentiment'] = lb.fit_transform(df['sentiment'])\n"
      ],
      "metadata": {
        "id": "qe1MyJ5Btw9n"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(num_words=500, split=' ')\n",
        "tokenizer.fit_on_texts(df['text'].values)\n",
        "X = tokenizer.texts_to_sequences(df['text'].values)\n",
        "X = pad_sequences(X)"
      ],
      "metadata": {
        "id": "j0POsFm2t1dN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(500, 120, input_length = X.shape[1]))\n",
        "model.add(SpatialDropout1D(0.4))\n",
        "model.add(LSTM(176, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(3,activation='softmax'))\n",
        "\n",
        "model.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics = ['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJq58tJgt4wt",
        "outputId": "89ef7a9c-e4c3-4c3e-9a7c-f587382e134c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 5, 120)            60000     \n",
            "                                                                 \n",
            " spatial_dropout1d_1 (Spati  (None, 5, 120)            0         \n",
            " alDropout1D)                                                    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 176)               209088    \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 3)                 531       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 269619 (1.03 MB)\n",
            "Trainable params: 269619 (1.03 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data into training and testing\n",
        "y=pd.get_dummies(df['sentiment'])\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)"
      ],
      "metadata": {
        "id": "cS83Hw4It74s"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "# Convert integer labels to one-hot encoded labels\n",
        "y_train_encoded = to_categorical(y_train, num_classes=3)\n"
      ],
      "metadata": {
        "id": "-IKZTNPPt_oN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "a3BsrPLJ09TP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train,y_train,epochs=10,batch_size=32,verbose='auto')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTSF10zH1BB2",
        "outputId": "7ad7d7dd-59c9-468f-a258-62b0ad37f6eb"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "18/18 [==============================] - 5s 54ms/step - loss: 1.0695 - accuracy: 0.4347\n",
            "Epoch 2/10\n",
            "18/18 [==============================] - 1s 46ms/step - loss: 1.0383 - accuracy: 0.4597\n",
            "Epoch 3/10\n",
            "18/18 [==============================] - 1s 53ms/step - loss: 1.0090 - accuracy: 0.4687\n",
            "Epoch 4/10\n",
            "18/18 [==============================] - 1s 52ms/step - loss: 0.9531 - accuracy: 0.5581\n",
            "Epoch 5/10\n",
            "18/18 [==============================] - 1s 50ms/step - loss: 0.8186 - accuracy: 0.6673\n",
            "Epoch 6/10\n",
            "18/18 [==============================] - 1s 60ms/step - loss: 0.6503 - accuracy: 0.7460\n",
            "Epoch 7/10\n",
            "18/18 [==============================] - 1s 54ms/step - loss: 0.5222 - accuracy: 0.8497\n",
            "Epoch 8/10\n",
            "18/18 [==============================] - 1s 83ms/step - loss: 0.3953 - accuracy: 0.9088\n",
            "Epoch 9/10\n",
            "18/18 [==============================] - 2s 84ms/step - loss: 0.3267 - accuracy: 0.9141\n",
            "Epoch 10/10\n",
            "18/18 [==============================] - 1s 70ms/step - loss: 0.2897 - accuracy: 0.9141\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79b8a61b18a0>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    }
  ]
}